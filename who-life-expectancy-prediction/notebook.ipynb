{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>...</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malta</td>\n",
       "      <td>2008</td>\n",
       "      <td>Developed</td>\n",
       "      <td>80.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>2655.573684</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>21928.767000</td>\n",
       "      <td>49379.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.813</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Congo</td>\n",
       "      <td>2005</td>\n",
       "      <td>Developing</td>\n",
       "      <td>55.3</td>\n",
       "      <td>394.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>62.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.496</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Burkina Faso</td>\n",
       "      <td>2009</td>\n",
       "      <td>Developing</td>\n",
       "      <td>56.9</td>\n",
       "      <td>283.0</td>\n",
       "      <td>44</td>\n",
       "      <td>4.55</td>\n",
       "      <td>81.143047</td>\n",
       "      <td>92.0</td>\n",
       "      <td>54118</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.41</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>552.745552</td>\n",
       "      <td>1514199.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.356</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guinea-Bissau</td>\n",
       "      <td>2011</td>\n",
       "      <td>Developing</td>\n",
       "      <td>57.1</td>\n",
       "      <td>289.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.57</td>\n",
       "      <td>40.453674</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>5.46</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>692.699890</td>\n",
       "      <td>1596154.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.410</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>2007</td>\n",
       "      <td>Developing</td>\n",
       "      <td>64.5</td>\n",
       "      <td>217.0</td>\n",
       "      <td>58</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.530573</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1088</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>41.451000</td>\n",
       "      <td>49171586.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.484</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  Year      Status  Life expectancy  Adult Mortality  \\\n",
       "0          Malta  2008   Developed             80.0             64.0   \n",
       "1          Congo  2005  Developing             55.3            394.0   \n",
       "2   Burkina Faso  2009  Developing             56.9            283.0   \n",
       "3  Guinea-Bissau  2011  Developing             57.1            289.0   \n",
       "4        Myanmar  2007  Developing             64.5            217.0   \n",
       "\n",
       "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
       "0              0     7.14             2655.573684         86.0         1  ...   \n",
       "1              8     2.03                0.000000          NaN       146  ...   \n",
       "2             44     4.55               81.143047         92.0     54118  ...   \n",
       "3              4     3.57               40.453674         86.0         0  ...   \n",
       "4             58     0.26                0.530573         85.0      1088  ...   \n",
       "\n",
       "   Polio  Total expenditure  Diphtheria    HIV/AIDS           GDP  Population  \\\n",
       "0   72.0               8.15         72.0        0.1  21928.767000     49379.0   \n",
       "1   62.0               2.42         62.0        5.9           NaN         NaN   \n",
       "2   91.0               7.41         92.0        1.1    552.745552   1514199.0   \n",
       "3   85.0               5.46         86.0        5.7    692.699890   1596154.0   \n",
       "4   84.0               1.68         86.0        0.6     41.451000  49171586.0   \n",
       "\n",
       "    thinness  1-19 years   thinness 5-9 years  \\\n",
       "0                    0.7                  0.7   \n",
       "1                    8.8                  8.5   \n",
       "2                    9.3                  8.8   \n",
       "3                    7.8                  7.7   \n",
       "4                   13.2                 13.5   \n",
       "\n",
       "   Income composition of resources  Schooling  \n",
       "0                            0.813       14.6  \n",
       "1                            0.496        9.4  \n",
       "2                            0.356        5.9  \n",
       "3                            0.410        9.0  \n",
       "4                            0.484        8.1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"training data.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop([\"Country\"], axis=1)\n",
    "train_df.dropna(subset=['Life expectancy'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, columns=[\"Status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop([\"Life expectancy\"], axis=1)\n",
    "y = train_df[[\"Life expectancy\"]].to_numpy().reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed = knn_imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import sys, os\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "poly_ker = PolynomialFeatures(degree=1)\n",
    "X_pol = poly_ker.fit_transform(X_imputed)\n",
    "# X_test_pol = poly_ker.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_pol)\n",
    "# X_test_scaled = scaler.transform(X_test_pol)\n",
    "\n",
    "# Convert scaled data back to a DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3402\n",
      "[LightGBM] [Info] Number of data points in the train set: 2050, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 69.395610\n"
     ]
    }
   ],
   "source": [
    "LGBModel = lgb.LGBMRegressor()\n",
    "LGBModel.fit(X_scaled, y)\n",
    "X_new = X_scaled.copy()\n",
    "X_new['Hardness_pred'] = LGBModel.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826810576701616"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_scaled, y)\n",
    "lin_reg.score(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ridge Regression GridSearchCV with Polynomial features\n",
    "# ridge_poly_pipeline = make_pipeline(PolynomialFeatures(), StandardScaler(), Ridge())\n",
    "# ridge_poly_params = {\n",
    "#     # 'polynomialfeatures__degree': [1, 2, 3],  # Example degree values for Polynomial features\n",
    "#     'ridge__alpha': [1, 0.1, 10.0, 20, 50]\n",
    "# }\n",
    "# ridge_poly_grid = GridSearchCV(ridge_poly_pipeline, param_grid=ridge_poly_params, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "# ridge_poly_grid.fit(X_train, y_train)\n",
    "\n",
    "# # Lasso Regression GridSearchCV with Polynomial features\n",
    "# lasso_poly_pipeline = make_pipeline(PolynomialFeatures(), StandardScaler(), Lasso())\n",
    "# lasso_poly_params = {\n",
    "#     # 'polynomialfeatures__degree': [2, 3, 4],  # Example degree values for Polynomial features\n",
    "#     'lasso__alpha': [1e-2, 1e-3, 1e-4, 1e-5]\n",
    "# }\n",
    "# lasso_poly_grid = GridSearchCV(lasso_poly_pipeline, param_grid=lasso_poly_params, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "# lasso_poly_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LightGBM Regression GridSearchCV\n",
    "# lgb_pipeline = make_pipeline(PolynomialFeatures(), StandardScaler(), lgb.LGBMRegressor(verbose=-1))\n",
    "# lgb_params = {\n",
    "#     'lgbmregressor__n_estimators': [100, 200],\n",
    "#     'lgbmregressor__learning_rate': [0.05, 0.1],\n",
    "#     'lgbmregressor__max_depth': [3, 4]\n",
    "# }\n",
    "# lgb_grid = GridSearchCV(lgb_pipeline, param_grid=lgb_params, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "# lgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest Regression GridSearchCV\n",
    "# rnf_pipeline = make_pipeline(PolynomialFeatures(), StandardScaler(), RandomForestRegressor())\n",
    "# rnf_params = {\n",
    "#     'randomforestregressor__n_estimators': [300, 400],\n",
    "#     'randomforestregressor__max_depth': [15, 20]\n",
    "# }\n",
    "# rnf_grid = GridSearchCV(rnf_pipeline, param_grid=rnf_params, cv=5, scoring=\"neg_mean_absolute_error\", n_jobs=-1)\n",
    "# rnf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Define a custom callback\n",
    "class PrintEpochLoss(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch} - Loss: {logs['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return tfp.stats.windowed_mean(tf.abs(y_true - y_pred))\n",
    "def metric_fn(y_true, y_pred):\n",
    "    return tfp.stats.percentile(tf.abs(y_true - y_pred), q=100) - tfp.stats.percentile(tf.abs(y_true - y_pred), q=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, verbose=2, mode='min', restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, min_lr=0.00001),\n",
    "    tf.keras.callbacks.TerminateOnNaN(),\n",
    "    PrintEpochLoss()\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "nn_model = Sequential([\n",
    "    InputLayer(input_shape=(X_new.shape[1],)),\n",
    "    BatchNormalization(epsilon=0.00001),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(64, activation='sigmoid'),\n",
    "    Dense(32, activation='sigmoid'),\n",
    "    Dense(1)  # Single output node for regression\n",
    "])\n",
    "\n",
    "# Compile the model with Mean Absolute Error (MAE) as the metric\n",
    "nn_model.compile(optimizer=Adam(0.013, beta_1=0.5), loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Loss: 57.92087936401367\n",
      "Epoch 50 - Loss: 1.3829365968704224\n",
      "Epoch 100 - Loss: 1.4581743478775024\n",
      "Epoch 150 - Loss: 1.4402942657470703\n",
      "Epoch 200 - Loss: 1.4215245246887207\n",
      "Epoch 250 - Loss: 1.3654329776763916\n",
      "Epoch 300 - Loss: 1.4613370895385742\n",
      "Restoring model weights from the end of the best epoch: 138.\n",
      "Epoch 338: early stopping\n"
     ]
    }
   ],
   "source": [
    "print_epoch_loss = PrintEpochLoss()\n",
    "\n",
    "# Train the model on the training data\n",
    "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model on the training data with the defined callback\n",
    "history = nn_model.fit(\n",
    "    X_train_val, y_train_val, \n",
    "    epochs=500,\n",
    "    batch_size=32,\n",
    "    class_weight=LGBModel.class_weight,\n",
    "    validation_data=(X_test_val, y_test_val), \n",
    "    callbacks=callbacks_list,\n",
    "    verbose=0  # Set verbose to 0 to avoid redundant output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on test data: 0.8637043237686157\n",
      "65/65 [==============================] - 0s 1ms/step\n",
      "Mean Absolute Error: 0.8465575680616426\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "mae = nn_model.evaluate(X_test_val, y_test_val, verbose=0)\n",
    "print(f\"MAE on test data: {mae}\")\n",
    "\n",
    "# Predictions on test data\n",
    "y_pred = nn_model.predict(X_new)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "mae_score = mean_absolute_error(y, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the best models\n",
    "# ridge_poly_best = ridge_poly_grid.best_estimator_\n",
    "# lasso_poly_best = lasso_poly_grid.best_estimator_\n",
    "# # gb_poly_best = gb_grid.best_estimator_\n",
    "# # lgb_best = lgb_grid.best_estimator_\n",
    "# rnf_best = rnf_grid.best_estimator_\n",
    "\n",
    "# # Evaluate on test data\n",
    "# ridge_poly_score = ridge_poly_best.score(X_test, y_test)\n",
    "# lasso_poly_score = lasso_poly_best.score(X_test, y_test)\n",
    "# # gb_poly_score = gb_poly_best.score(X_test, y_test)\n",
    "# # lgb_score = lgb_best.score(X_test, y_test)\n",
    "# rnf_score = rnf_best.score(X_test, y_test)\n",
    "\n",
    "# # Print the best parameters and score\n",
    "# print(\"Best Parameters for Ridge Regression:\", ridge_poly_grid.best_params_)\n",
    "# print(\"Ridge Regression Score:\", ridge_poly_score)\n",
    "\n",
    "# # Print the best parameters and score\n",
    "# print(\"Best Parameters for Lasso Regression:\", lasso_poly_grid.best_params_)\n",
    "# print(\"Lasso Regression Score:\", lasso_poly_score)\n",
    "\n",
    "# # # Print the best parameters and score\n",
    "# # print(\"Best Parameters for Gradient Boosting:\", gb_grid.best_params_)\n",
    "# # print(f'Gradient Boosting Score: {gb_score}')\n",
    "\n",
    "# # # Print LightGBM score \n",
    "# # print(\"Best Parameters for LightGBM:\", lgb_grid.best_params_)\n",
    "# # print(f'LightGBM Score: {lgb_score}')\n",
    "\n",
    "# # Print Random Forest Regression score \n",
    "# print(\"Best Parameters for Random Forest Regression:\", rnf_grid.best_params_)\n",
    "# print(f'Random Forest Regression Score: {rnf_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"testing data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop([\"Country\", \"Row_id\"], axis=1)\n",
    "X_test = pd.get_dummies(X_test, columns=[\"Status\"])\n",
    "X_test_imputed = knn_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = poly_ker.transform(X_test_imputed)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert scaled data back to a DataFrame\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = X_test.copy()\n",
    "X_test_new['Hardness_pred'] = LGBModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = nn_model.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv of y_test with columns \"id\" and \"Hardness\"\n",
    "y_test_df = pd.DataFrame({'Row_id': test_df['Row_id'], 'Life expectancy ': y_test.reshape((-1,))})\n",
    "y_test_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
